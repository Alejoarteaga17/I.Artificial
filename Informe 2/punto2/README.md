# Actividad 2 ‚Äî Random Forest

**Autor:** *(tu nombre)*  
**Fecha:** *(fecha de entrega)*

---

## 1. Descripci√≥n del dataset

- **Fuente:** Dataset `fetch_california_housing.csv` proporcionado por el curso.
- **N√∫mero de registros:** 20 640
- **N√∫mero de variables:** 9 columnas
  - **Variables predictoras:**  
    `MedInc` (ingreso medio), `HouseAge` (edad promedio de casas),  
    `AveRooms` (habitaciones promedio), `AveBedrms` (dormitorios promedio),  
    `Population`, `AveOccup` (ocupantes promedio), `Latitude`, `Longitude`.
  - **Variable objetivo:**  
    `MedHouseVal` ‚Äî valor medio de las viviendas.
- **Tipo de problema:** Regresi√≥n (predicci√≥n de un valor num√©rico continuo).

---

## 2. Preprocesamiento realizado

**a. Limpieza de datos faltantes**  
- Se aplic√≥ `SimpleImputer(strategy='median')` para rellenar valores nulos num√©ricos.
- No se detectaron valores faltantes en el dataset.

**b. Codificaci√≥n de variables categ√≥ricas**  
- No existen variables categ√≥ricas en este dataset, por lo que no se aplic√≥ codificaci√≥n.

**c. Escalado / normalizaci√≥n**  
- Se aplic√≥ `StandardScaler` dentro del `Pipeline` para escalar las variables num√©ricas.
- Aunque Random Forest no lo requiere, se incluy√≥ por buenas pr√°cticas.

**d. Divisi√≥n en train/test**  
- Se utiliz√≥ `train_test_split` con 80% para entrenamiento y 20% para prueba.
- `random_state=42` para asegurar reproducibilidad.

---

## 3. Entrenamiento del modelo (Random Forest con Pipeline)

Se construy√≥ un `Pipeline` con tres etapas:

1. `SimpleImputer(strategy='median')`
2. `StandardScaler()`
3. `RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)`

El modelo fue entrenado con el conjunto de entrenamiento y luego evaluado con el conjunto de prueba.

> ‚ö†Ô∏è Nota: El enunciado ped√≠a tres modelos, pero en este trabajo solo se implement√≥ **Random Forest**, siguiendo las indicaciones de la actividad.

---

## 4. Evaluaci√≥n de resultados

**a. M√©tricas de rendimiento en test**

| M√©trica | Valor aproximado |
|---------|---------|
| MAE     | 0.33    |
| MSE     | 0.26    |
| RMSE    | 0.51    |
| R¬≤      | 0.80    |

**b. Visualizaciones**

1. **Importancia de caracter√≠sticas**  
   ![Gr√°fico de importancia de caracter√≠sticas](resultados/feature_importances.png)

2. **Real vs Predicho**  
   ![Scatter real vs predicho](resultados/real_vs_predicho.png)

(Estas gr√°ficas se muestran en pantalla al ejecutar el script y tambi√©n pueden guardarse como `.png`).

---

## 5. An√°lisis comparativo

Aunque no se entrenaron los otros dos modelos, se describe brevemente un posible an√°lisis:

| Modelo           | Ventajas                                   | Desventajas                              | Posibles usos                     |
|------------------|---------------------------------------------|--------------------------------------------|-------------------------------------|
| √Årbol de decisi√≥n simple | F√°cil de interpretar | Tiende a sobreajustar | Problemas simples, interpretables |
| Random Forest    | Robusto, buen desempe√±o general, reduce sobreajuste | M√°s lento y menos interpretable | Datasets grandes y variados |
| Red Neuronal     | Alta capacidad predictiva en datos complejos | Requiere mucho ajuste y datos grandes | Datos no lineales, visi√≥n, audio |

En este caso, **Random Forest ofrece un balance ideal entre rendimiento y facilidad de uso** para este dataset.

---

## 6. Conclusiones

- Se logr√≥ predecir el valor medio de viviendas en California con un desempe√±o bueno (R¬≤ ‚âà 0.80).
- La variable m√°s influyente fue el ingreso medio (`MedInc`), lo que es coherente con el dominio del problema.
- Random Forest demostr√≥ ser robusto, preciso y f√°cil de implementar mediante un `Pipeline`.
- Como mejoras futuras se podr√≠a:
  - Ajustar hiperpar√°metros con `GridSearchCV` o `RandomizedSearchCV`
  - Probar modelos de boosting como `XGBoost` o `LightGBM`
  - Incluir validaci√≥n cruzada y comparar con otros algoritmos.

---

## üìÇ Archivos entregados

- `actividad2_random_forest.py` ‚Äî Script completo con el pipeline y entrenamiento
- `README.md` ‚Äî Este informe
- Carpeta `resultados/` con:
  - `random_forest_pipeline.pkl`
  - `rf_metrics.csv`
  - `rf_results.csv`
  - `rf_feature_importances.csv`
